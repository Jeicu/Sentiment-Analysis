{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get data from excel file\n",
    "def get_all_data():\n",
    "    data = pd.read_csv('EmotionWheel3.csv')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of uppercase, new lines, non-alphabetical characters\n",
    "def preprocess_data(data):\n",
    "    for i in range(len(data)):\n",
    "        data['Lyrics'][i] = data['Lyrics'][i].lower()\n",
    "        data['Lyrics'][i] = data['Lyrics'][i].replace('\\n',' ')\n",
    "        data['Lyrics'][i] = ''.join(c for c in data['Lyrics'][i] if c.isalpha() | (c == ' '))\n",
    "        #print(data['Lyrics'][i])\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model\n",
    "def training_step(training_data, vectorizer):\n",
    "    training_text = []\n",
    "    training_result = []\n",
    "    #separate features and labels\n",
    "    for i in range(len(training_data)):\n",
    "        training_text.append(training_data[i][0])\n",
    "        training_result.append(training_data[i][1])\n",
    "    training_text = vectorizer.fit_transform(training_text)   \n",
    "    classifier = MultinomialNB().fit(training_text, training_result) #remove toarray for bernoulli/multi\n",
    "#     print(\"Classifier: \" + str(classifier))\n",
    "#     print(\"Classifier log prior: \" + str(classifier.class_log_prior_))\n",
    "#     print(\"Feature log prob: \" + str(classifier.feature_log_prob_))\n",
    "    classifier.get_params()\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return block of text and its classifier prediction\n",
    "def analyze_text(classifier, vectorizer, text):\n",
    "#     print(\"Classifier prediction: \" + str(classifier.predict(vectorizer.transform([text]))))\n",
    "    return text, classifier.predict(vectorizer.transform([text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate model performance\n",
    "def evaluate(evaluation_data):\n",
    "    evaluation_text = []\n",
    "    actual_result = []\n",
    "    #separate features/labels\n",
    "    for i in range(len(evaluation_data)):\n",
    "        evaluation_text.append(evaluation_data[i][0])\n",
    "        actual_result.append(int(evaluation_data[i][1]))\n",
    "    #check accuracy of classifier on evaluation data\n",
    "    total = len(evaluation_text)\n",
    "    corrects = 0\n",
    "    for i in range(0, total):\n",
    "        result = classifier.predict(vectorizer.transform([evaluation_text[i]])) #remove toarray\n",
    "        text = evaluation_text[i]\n",
    "        corrects += 1 if result[0] == actual_result[i] else 0\n",
    "    print(\"Accuracy: \", corrects * 100 / total)\n",
    "    return \"Accuracy: \", corrects * 100 / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "data = preprocess_data(get_all_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  82.85714285714286\n",
      "Accuracy:  80.0\n",
      "Accuracy:  80.0\n",
      "Accuracy:  82.85714285714286\n",
      "Accuracy:  81.9047619047619\n",
      "Accuracy:  78.0952380952381\n",
      "Accuracy:  78.0952380952381\n",
      "Accuracy:  77.14285714285714\n",
      "Accuracy:  81.9047619047619\n",
      "Accuracy:  75.23809523809524\n",
      "Accuracy:  75.23809523809524\n",
      "Accuracy:  81.9047619047619\n",
      "Accuracy:  81.9047619047619\n",
      "Accuracy:  79.04761904761905\n",
      "Accuracy:  79.04761904761905\n",
      "Accuracy:  81.9047619047619\n",
      "Accuracy:  83.65384615384616\n",
      "Accuracy:  77.88461538461539\n",
      "Accuracy:  77.88461538461539\n",
      "Accuracy:  81.73076923076923\n"
     ]
    }
   ],
   "source": [
    "#cross validation\n",
    "cv = KFold(n_splits=5)\n",
    "#check which vectorizer works best\n",
    "v = [CountVectorizer(binary = 'true'), TfidfVectorizer(binary = 'true'), TfidfVectorizer(), CountVectorizer()]\n",
    "for train_index, test_index in cv.split(data): \n",
    "    training_data = []\n",
    "    evaluation_data = []\n",
    "    #check for performance on specific emotion\n",
    "    for indice in range(len(data)): \n",
    "        if indice in train_index:\n",
    "            training_data.append([data['Lyrics'][indice],data['Surprise'][indice]])\n",
    "        else: \n",
    "            evaluation_data.append([data['Lyrics'][indice],data['Disgust'][indice]])\n",
    "    for vectorizer in v: \n",
    "        classifier = training_step(training_data, vectorizer)\n",
    "        evaluate(evaluation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28.  2.  1. ...  0.  4.  2.]\n",
      " [ 0.  0.  0. ...  1.  5.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(classifier.feature_count_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix(evaluation_data):\n",
    "    evaluation_text     = [evaluation_data[0] for evaluation_data in evaluation_data]\n",
    "    actual_result       = [int(evaluation_data[1]) for evaluation_data in evaluation_data]\n",
    "    prediction_result   = []\n",
    "    print(actual_result)\n",
    "    for text in evaluation_text:\n",
    "        analysis_result = analyze_text(classifier, vectorizer, text)\n",
    "        prediction_result.append(int(analysis_result[1][0]))\n",
    "    print(prediction_result)\n",
    "#     print(evaluation_text[9])\n",
    "    matrix = confusion_matrix(actual_result, prediction_result)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "[0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negatives</th>\n",
       "      <th>Positives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negatives</th>\n",
       "      <td>75</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positives</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Negatives  Positives\n",
       "Negatives         75          6\n",
       "Positives         13         10"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = create_confusion_matrix(evaluation_data)\n",
    "pd.DataFrame(\n",
    "    result, \n",
    "    columns=[\"Negatives\", \"Positives\"],\n",
    "    index=[\"Negatives\", \"Positives\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(result):\n",
    "    text, analysis_result = result\n",
    "    print(analysis_result)\n",
    "    print_text = \"Positive\" if analysis_result[0] == 1 else \"Negative\"\n",
    "    print(text, \":\", print_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "you are all i need coming from a guy thats on his knees at least say its fine but honestly i cant believe it that you aint leavin the world keeps testing me what can we expect i am only  you say i am alright but i am far too weak i cant believe it that you aint leavin i know that ive hurt you believe when i say i never meant too treat you this way deserve much better im such a cliché what does it matter and did it crush your mind cause i see a strange look in your eyes and every time its there i paralyze my heart stops with beating afraid that you leavin i know that ive hurt you believe when i say i never meant too treat you this way deserve much better im such a cliche what does it matter i know that ive hurt you believe when i say i never meant too treat you this way deserve much better im such a cliché what does it matter do you think youre better off alone do you think youre better off alone you think youre better off alone you think youre better off alone i know that ive hurt you believe when i say i never meant too treat you this way deserve much better im such a cliché what does it matter do you think youre better off alone do you think youre better off alone : Negative\n",
      "[0]\n",
      "said he tried to phone me but i never have time he said that i never listen but i dont even try i got a new place in cali but im gone every night so i fill it with strangers so they keep em alive she said she told you she knows me but the face isnt right she asked if i recognized her and i told her i might see everywhere i go i got a million different people tryna kick it but im still alone in my mind i know youre dying to meet me but i can just tell you this baby as soon as you meet me youll wish that you never did youll wish that you never did i stayed a night out in paris where they dont know my name and i got into some trouble with that drink in my veins i got a problem with parties cause its loud in my brain and i can never say sorry cause i wont take the blame i know i always go missing and youre lying awake but if you ask why im distant oh im runnin away you know that everywhere i go i got a million different people tryna kick it but im still alone in my mind i know youre dying to meet me but i can just tell you this baby as soon as you meet me youll wish that you never did youll wish that you never did i i know you wanna i i know you wanna i i know you wanna slip under my armor i i know you wanna i i know you wanna i i know you wanna slip under my armor see everywhere i go i got a million different people tryna hit it but im still alone in my mind i know youre dying to meet me but i can just tell you this baby as soon as you meet me youll wish that you never did youll wish that you never did yeah yeah youll wish that you never did i know you wanna slip under my armor oh i know you wanna i i know you wanna youll wish that you never did : Negative\n",
      "[0]\n",
      "kick mind dying to me just tell you as soon stayed paris they my name never say sorry lying awake why : Negative\n",
      "[0]\n",
      "paris : Negative\n",
      "[0]\n",
      "lying awake why : Negative\n"
     ]
    }
   ],
   "source": [
    "print_result(analyze_text(classifier, vectorizer, \"you are all i need coming from a guy thats on his knees at least say its fine but honestly i cant believe it that you aint leavin the world keeps testing me what can we expect i am only  you say i am alright but i am far too weak i cant believe it that you aint leavin i know that ive hurt you believe when i say i never meant too treat you this way deserve much better im such a cliché what does it matter and did it crush your mind cause i see a strange look in your eyes and every time its there i paralyze my heart stops with beating afraid that you leavin i know that ive hurt you believe when i say i never meant too treat you this way deserve much better im such a cliche what does it matter i know that ive hurt you believe when i say i never meant too treat you this way deserve much better im such a cliché what does it matter do you think youre better off alone do you think youre better off alone you think youre better off alone you think youre better off alone i know that ive hurt you believe when i say i never meant too treat you this way deserve much better im such a cliché what does it matter do you think youre better off alone do you think youre better off alone\"))\n",
    "print_result(analyze_text(classifier, vectorizer, \"said he tried to phone me but i never have time he said that i never listen but i dont even try i got a new place in cali but im gone every night so i fill it with strangers so they keep em alive she said she told you she knows me but the face isnt right she asked if i recognized her and i told her i might see everywhere i go i got a million different people tryna kick it but im still alone in my mind i know youre dying to meet me but i can just tell you this baby as soon as you meet me youll wish that you never did youll wish that you never did i stayed a night out in paris where they dont know my name and i got into some trouble with that drink in my veins i got a problem with parties cause its loud in my brain and i can never say sorry cause i wont take the blame i know i always go missing and youre lying awake but if you ask why im distant oh im runnin away you know that everywhere i go i got a million different people tryna kick it but im still alone in my mind i know youre dying to meet me but i can just tell you this baby as soon as you meet me youll wish that you never did youll wish that you never did i i know you wanna i i know you wanna i i know you wanna slip under my armor i i know you wanna i i know you wanna i i know you wanna slip under my armor see everywhere i go i got a million different people tryna hit it but im still alone in my mind i know youre dying to meet me but i can just tell you this baby as soon as you meet me youll wish that you never did youll wish that you never did yeah yeah youll wish that you never did i know you wanna slip under my armor oh i know you wanna i i know you wanna youll wish that you never did\"))\n",
    "print_result(analyze_text(classifier, vectorizer, \"kick mind dying to me just tell you as soon stayed paris they my name never say sorry lying awake why\"))\n",
    "print_result(analyze_text(classifier, vectorizer, \"paris\"))\n",
    "print_result(analyze_text(classifier, vectorizer, \"lying awake why\"))\n",
    "#correlation between ad cost and positive/negative reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "i cant wait : Negative\n"
     ]
    }
   ],
   "source": [
    "print_result(analyze_text(classifier, vectorizer, \"i cant wait\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = pd.read_csv('EmotionLexicon.txt', sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon.columns=[\"Word\", \"Emotion\", \"Presence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = lexicon[(lexicon.Emotion != 'negative') & (lexicon.Emotion != 'positive')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Presence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aback</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aback</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aback</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aback</td>\n",
       "      <td>fear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aback</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aback</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aback</td>\n",
       "      <td>surprise</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aback</td>\n",
       "      <td>trust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>abacus</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abacus</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>abacus</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>abacus</td>\n",
       "      <td>fear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>abacus</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>abacus</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>abacus</td>\n",
       "      <td>surprise</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>abacus</td>\n",
       "      <td>trust</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>abandon</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>abandon</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>abandon</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>abandon</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>abandon</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>abandon</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>abandon</td>\n",
       "      <td>surprise</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>abandon</td>\n",
       "      <td>trust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>anger</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>fear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>sadness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113426</th>\n",
       "      <td>zoo</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113427</th>\n",
       "      <td>zoo</td>\n",
       "      <td>fear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113428</th>\n",
       "      <td>zoo</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113429</th>\n",
       "      <td>zoo</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113430</th>\n",
       "      <td>zoo</td>\n",
       "      <td>surprise</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113431</th>\n",
       "      <td>zoo</td>\n",
       "      <td>trust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113432</th>\n",
       "      <td>zoological</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113433</th>\n",
       "      <td>zoological</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113434</th>\n",
       "      <td>zoological</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113435</th>\n",
       "      <td>zoological</td>\n",
       "      <td>fear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113436</th>\n",
       "      <td>zoological</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113437</th>\n",
       "      <td>zoological</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113438</th>\n",
       "      <td>zoological</td>\n",
       "      <td>surprise</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113439</th>\n",
       "      <td>zoological</td>\n",
       "      <td>trust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113440</th>\n",
       "      <td>zoology</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113441</th>\n",
       "      <td>zoology</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113442</th>\n",
       "      <td>zoology</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113443</th>\n",
       "      <td>zoology</td>\n",
       "      <td>fear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113444</th>\n",
       "      <td>zoology</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113445</th>\n",
       "      <td>zoology</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113446</th>\n",
       "      <td>zoology</td>\n",
       "      <td>surprise</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113447</th>\n",
       "      <td>zoology</td>\n",
       "      <td>trust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113448</th>\n",
       "      <td>zoom</td>\n",
       "      <td>anger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113449</th>\n",
       "      <td>zoom</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113450</th>\n",
       "      <td>zoom</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113451</th>\n",
       "      <td>zoom</td>\n",
       "      <td>fear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113452</th>\n",
       "      <td>zoom</td>\n",
       "      <td>joy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113453</th>\n",
       "      <td>zoom</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113454</th>\n",
       "      <td>zoom</td>\n",
       "      <td>surprise</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113455</th>\n",
       "      <td>zoom</td>\n",
       "      <td>trust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113456 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word       Emotion  Presence\n",
       "0            aback         anger         0\n",
       "1            aback  anticipation         0\n",
       "2            aback       disgust         0\n",
       "3            aback          fear         0\n",
       "4            aback           joy         0\n",
       "5            aback       sadness         0\n",
       "6            aback      surprise         0\n",
       "7            aback         trust         0\n",
       "8           abacus         anger         0\n",
       "9           abacus  anticipation         0\n",
       "10          abacus       disgust         0\n",
       "11          abacus          fear         0\n",
       "12          abacus           joy         0\n",
       "13          abacus       sadness         0\n",
       "14          abacus      surprise         0\n",
       "15          abacus         trust         1\n",
       "16         abandon         anger         0\n",
       "17         abandon  anticipation         0\n",
       "18         abandon       disgust         0\n",
       "19         abandon          fear         1\n",
       "20         abandon           joy         0\n",
       "21         abandon       sadness         1\n",
       "22         abandon      surprise         0\n",
       "23         abandon         trust         0\n",
       "24       abandoned         anger         1\n",
       "25       abandoned  anticipation         0\n",
       "26       abandoned       disgust         0\n",
       "27       abandoned          fear         1\n",
       "28       abandoned           joy         0\n",
       "29       abandoned       sadness         1\n",
       "...            ...           ...       ...\n",
       "113426         zoo       disgust         0\n",
       "113427         zoo          fear         0\n",
       "113428         zoo           joy         0\n",
       "113429         zoo       sadness         0\n",
       "113430         zoo      surprise         0\n",
       "113431         zoo         trust         0\n",
       "113432  zoological         anger         0\n",
       "113433  zoological  anticipation         0\n",
       "113434  zoological       disgust         0\n",
       "113435  zoological          fear         0\n",
       "113436  zoological           joy         0\n",
       "113437  zoological       sadness         0\n",
       "113438  zoological      surprise         0\n",
       "113439  zoological         trust         0\n",
       "113440     zoology         anger         0\n",
       "113441     zoology  anticipation         0\n",
       "113442     zoology       disgust         0\n",
       "113443     zoology          fear         0\n",
       "113444     zoology           joy         0\n",
       "113445     zoology       sadness         0\n",
       "113446     zoology      surprise         0\n",
       "113447     zoology         trust         0\n",
       "113448        zoom         anger         0\n",
       "113449        zoom  anticipation         0\n",
       "113450        zoom       disgust         0\n",
       "113451        zoom          fear         0\n",
       "113452        zoom           joy         0\n",
       "113453        zoom       sadness         0\n",
       "113454        zoom      surprise         0\n",
       "113455        zoom         trust         0\n",
       "\n",
       "[113456 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeWeights(emotionArray, newWord):\n",
    "    temp = lexicon[lexicon['Word'].values == newWord].reset_index(drop=True)\n",
    "    for i in range(8): \n",
    "        emotionArray[i] += temp['Presence'][i]\n",
    "    emotionArray[8] += 1\n",
    "    return emotionArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexiconize(words): \n",
    "    emotionArray = [0,0,0,0,0,0,0,0,0]\n",
    "    for word in words.split(): \n",
    "        if word in lexicon.values: \n",
    "            emotionPresence = changeWeights(emotionArray, word)\n",
    "    return emotionArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now need to feed in data, create random forest model for one emotion that takes emotionArray as input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manipulateData(training_data, evaluation_data): \n",
    "    print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "X_eval = []\n",
    "Y_train_anger = []\n",
    "Y_train_anticipation = []\n",
    "Y_train_joy = []\n",
    "Y_train_trust = []\n",
    "Y_train_fear = []\n",
    "Y_train_surprise = []\n",
    "Y_train_sadness = []\n",
    "Y_train_disgust = []\n",
    "Y_eval_anger = []\n",
    "Y_eval_anticipation = []\n",
    "Y_eval_joy = []\n",
    "Y_eval_trust = []\n",
    "Y_eval_fear = []\n",
    "Y_eval_surprise = []\n",
    "Y_eval_sadness = []\n",
    "Y_eval_disgust = []\n",
    "\n",
    "# print(training_data)\n",
    "# print(evaluation_data)\n",
    "#check for performance on specific emotion\n",
    "for indice in range(len(data)): \n",
    "    print(indice)\n",
    "    if indice < len(data)*0.8:         \n",
    "        X_train.append(lexiconize(data['Lyrics'][indice]))\n",
    "        Y_train_anger.append(data['Anger'][indice])\n",
    "        Y_train_anticipation.append(data['Anticipation'][indice])\n",
    "        Y_train_joy.append(data['Joy'][indice])\n",
    "        Y_train_trust.append(data['Trust'][indice])\n",
    "        Y_train_fear.append(data['Fear'][indice])\n",
    "        Y_train_surprise.append(data['Surprise'][indice])\n",
    "        Y_train_sadness.append(data['Sadness'][indice])\n",
    "        Y_train_disgust.append(data['Disgust'][indice])\n",
    "    else: \n",
    "        X_eval.append(lexiconize(data['Lyrics'][indice]))\n",
    "        Y_eval_anger.append(data['Anger'][indice])\n",
    "        Y_eval_anticipation.append(data['Anticipation'][indice])\n",
    "        Y_eval_joy.append(data['Joy'][indice])\n",
    "        Y_eval_trust.append(data['Trust'][indice])\n",
    "        Y_eval_fear.append(data['Fear'][indice])\n",
    "        Y_eval_surprise.append(data['Surprise'][indice])\n",
    "        Y_eval_sadness.append(data['Sadness'][indice])\n",
    "        Y_eval_disgust.append(data['Disgust'][indice])\n",
    "\n",
    "\n",
    "#manipulate data for random forest \n",
    "#new_train_data, new_eval_data = manipulateData(training_data, evaluation_data)\n",
    "#do random forest \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "def create_and_evaluate_rf(X_train, X_eval, Y_train, Y_eval): \n",
    "    clf = RandomForestClassifier(n_estimators=5)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    y_pred = clf.predict(X_eval)\n",
    "    print(\"Accuracy: \", metrics.accuracy_score(Y_eval, y_pred))\n",
    "    matrix = confusion_matrix(Y_eval, y_pred)\n",
    "    print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8076923076923077\n",
      "[[81  7]\n",
      " [13  3]]\n",
      "Accuracy:  0.5384615384615384\n",
      "[[30 28]\n",
      " [20 26]]\n",
      "Accuracy:  0.5288461538461539\n",
      "[[40 12]\n",
      " [37 15]]\n",
      "Accuracy:  0.6346153846153846\n",
      "[[22 18]\n",
      " [20 44]]\n",
      "Accuracy:  0.7403846153846154\n",
      "[[74 11]\n",
      " [16  3]]\n",
      "Accuracy:  0.7692307692307693\n",
      "[[80  2]\n",
      " [22  0]]\n",
      "Accuracy:  0.5865384615384616\n",
      "[[51 15]\n",
      " [28 10]]\n",
      "Accuracy:  0.7307692307692307\n",
      "[[66 15]\n",
      " [13 10]]\n"
     ]
    }
   ],
   "source": [
    "yTrains = [Y_train_anger, Y_train_anticipation, Y_train_joy, Y_train_trust, Y_train_fear, \n",
    "           Y_train_surprise, Y_train_sadness, Y_train_disgust]\n",
    "yEvals = [Y_eval_anger, Y_eval_anticipation, Y_eval_joy, Y_eval_trust, Y_eval_fear, \n",
    "           Y_eval_surprise, Y_eval_sadness, Y_eval_disgust]\n",
    "for i in range(len(yTrains)): \n",
    "    create_and_evaluate_rf(X_train, X_eval, yTrains[i], yEvals[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
